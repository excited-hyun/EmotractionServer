{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TestEmotion.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMokbld4XLx/Chqg3BlG/hv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzaoHxk59LWy","executionInfo":{"status":"ok","timestamp":1631619145559,"user_tz":-540,"elapsed":31226,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}},"outputId":"7f5164a5-61e0-43c1-bbb1-054e3ce0da17"},"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mxnet\n","  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n","\u001b[K     |████████████████████████████████| 46.9 MB 41 kB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595730 sha256=01d8c360ab0a13105ad4776f5718bfcb582f4c0cc0484c03cd7b213fd80f1141\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.0)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Collecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 30.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 37.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.8.1rc1 transformers-3.0.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4e-A7_EL-JwT","executionInfo":{"status":"ok","timestamp":1631619150583,"user_tz":-540,"elapsed":5037,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}},"outputId":"58f42692-a026-4ccc-b40b-2fbf39b58f9d"},"source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-od9pxk2l\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-od9pxk2l\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=12771 sha256=af1afc4febd219184e543ba527fb2c0258f3ccaf9f76ba884f557a178b86ae84\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-f70zfwvd/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","Successfully built kobert\n","Installing collected packages: kobert\n","Successfully installed kobert-0.1.2\n"]}]},{"cell_type":"code","metadata":{"id":"maBw1xIx9LJf","executionInfo":{"status":"ok","timestamp":1631619158606,"user_tz":-540,"elapsed":8035,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"OgAoKnON9RUL","executionInfo":{"status":"ok","timestamp":1631619161016,"user_tz":-540,"elapsed":2423,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8t5Y10f9USn","executionInfo":{"status":"ok","timestamp":1631619161019,"user_tz":-540,"elapsed":6,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ubvPzmj9as7","executionInfo":{"status":"ok","timestamp":1631619161020,"user_tz":-540,"elapsed":5,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["##GPU 사용 시\n","device = torch.device(\"cuda:0\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVXzjmqG-NPG","executionInfo":{"status":"ok","timestamp":1631619439115,"user_tz":-540,"elapsed":278100,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}},"outputId":"d97030a6-1eeb-4aa3-83da-d4655bed57a1"},"source":["bertmodel, vocab = get_pytorch_kobert_model()"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[██████████████████████████████████████████████████]\n","[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","metadata":{"id":"2LZCTdpgBip8","executionInfo":{"status":"ok","timestamp":1631619439115,"user_tz":-540,"elapsed":17,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"JurdHIXNBSyx","executionInfo":{"status":"ok","timestamp":1631619439116,"user_tz":-540,"elapsed":17,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["## Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 10\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kllZV3eEAmY","executionInfo":{"status":"ok","timestamp":1631619439116,"user_tz":-540,"elapsed":16,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}},"outputId":"fd400f18-83da-4ba3-ff15-740144821443"},"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model\n"]}]},{"cell_type":"code","metadata":{"id":"XFwpu3Ep-xET","executionInfo":{"status":"ok","timestamp":1631619439117,"user_tz":-540,"elapsed":15,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=7,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJavOd-fBBv0","executionInfo":{"status":"ok","timestamp":1631619448344,"user_tz":-540,"elapsed":9242,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"_29io8DqA39Y","executionInfo":{"status":"ok","timestamp":1631619448347,"user_tz":-540,"elapsed":15,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"e54WkNHPA4jO","executionInfo":{"status":"ok","timestamp":1631619448347,"user_tz":-540,"elapsed":14,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSY8qKyy8bkx","executionInfo":{"status":"ok","timestamp":1631619471601,"user_tz":-540,"elapsed":23267,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}},"outputId":"a412e34e-88b7-41aa-beb1-253fcd6d7999"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"sQ2rIvP08d9q","executionInfo":{"status":"ok","timestamp":1631619490270,"user_tz":-540,"elapsed":18672,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["#★★★현재경로가 model이 있는 폴더여야함★★★\n","import os\n","os.chdir('/content/drive/MyDrive/파이썬공부/챗봇/models/')\n","\n","model1 = torch.load('7emotions_model.pt')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n","model1.load_state_dict(torch.load('7emotions_model_state_dict.pt'))  # state_dict를 불러 온 후, 모델에 저장\n","\n","checkpoint = torch.load('7emotions_all.tar')   # dict 불러오기\n","model1.load_state_dict(checkpoint['model'])\n","optimizer.load_state_dict(checkpoint['optimizer'])"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRFaa-zV8oRB","executionInfo":{"status":"ok","timestamp":1631619490271,"user_tz":-540,"elapsed":21,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}},"outputId":"7bbe330f-edee-4fab-fdc8-aac09665f78d"},"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model\n"]}]},{"cell_type":"code","metadata":{"id":"itOkbVciEz46","executionInfo":{"status":"ok","timestamp":1631619490271,"user_tz":-540,"elapsed":18,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}}},"source":["def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model1.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model1(token_ids, valid_length, segment_ids)\n","\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 0:\n","                test_eval.append(\"공포가\")\n","            elif np.argmax(logits) == 1:\n","                test_eval.append(\"놀람이\")\n","            elif np.argmax(logits) == 2:\n","                test_eval.append(\"분노가\")\n","            elif np.argmax(logits) == 3:\n","                test_eval.append(\"슬픔이\")\n","            elif np.argmax(logits) == 4:\n","                test_eval.append(\"중립이\")\n","            elif np.argmax(logits) == 5:\n","                test_eval.append(\"행복이\")\n","            elif np.argmax(logits) == 6:\n","                test_eval.append(\"혐오가\")\n","\n","        print(test_eval[0] + \" 느껴집니다.\")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8E_rNTh28vZj","executionInfo":{"status":"ok","timestamp":1631620106230,"user_tz":-540,"elapsed":118552,"user":{"displayName":"신나현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16517821496124607546"}},"outputId":"3d1b9e2e-288e-4411-df83-54ebff6b8206"},"source":["#질문 무한반복하기!\n","end = 1\n","while end == 1 :\n","    sentence = input(\"말을 입력해주세요 : \")\n","    if sentence == \"0\" :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"],"execution_count":20,"outputs":[{"name":"stdout","output_type":"stream","text":["말을 입력해주세요 : 오늘 너무 피곤했어\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"name":"stdout","output_type":"stream","text":["슬픔이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 우와 맛있겠다\n","행복이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 어디야?\n","놀람이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 오늘 뭐했어\n","놀람이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 오늘 진짜 짜증나는 일 있었어\n","분노가 느껴집니다.\n","\n","\n","말을 입력해주세요 : 와 진짜 무섭더라\n","공포가 느껴집니다.\n","\n","\n","말을 입력해주세요 : 응\n","중립이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 그렇긴해\n","놀람이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 0\n"]}]}]}